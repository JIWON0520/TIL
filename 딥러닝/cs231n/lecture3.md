## Lecture 3 - Loss Functions and Optimization

lecture2 에서 linear classifier가 학습데이터를 학습하고 그 정보를 요약하여 metrix W에 압축한다고 했다. 이번 lecture3에서는 linear classifier가 어떻게 파라미터 W를 선택하는지 알아보자.

![사진1](https://user-images.githubusercontent.com/77263283/131453317-54c592ea-49ad-473e-9c57-4c3f407e24be.png)

우리는 가장 최선인 W를 찾기 위한 정량적인 방법이 필요하다. 이 W를 가지고 W가 얼마나 좋은지 안좋은지를 판별해주는 함수를 **'손실(loss) 함수'** 라고 한다. 

위의 예제에서 classifier는 세개의 이미지를 분류했는데, 이 분류기는 잘 작동하고 있지 않다. 자동차 이미지를 보면 자동차 스코어는 4.9로 다른 카테고리 스코어보다 충분히 높기 때문에 잘분류 되었지만, 개구리 이미지의 경우 정답인 개구리 스코어는 -3.1로 다른 카테고리 스코어보다 월등히 낮다.

손실 함수를 얘기 할때 고려해야 할것은 x와 y이다. x는 input값으로 사용되는 학습 데이터 세트이고 y는 알고리즘이 에측하는 예측값인 output이다. 

위의 수식에서 L_i 은 함수 f로부터 나온 예측 스코어와 실제 target값을 사용해서 이 알고리즘이 잘 작동하는지 알려주는 정량화된 지표이다.  최종 손실함수는 이 개개의 학습 데이터의 L_i의 값을 더해 평균을 취한 값이다. 

딥러닝 알고리즘 뿐만아니라 다른 알고리즘에서도 적용되는 가장 일반적인 일은 metrix W가 좋은지 안좋은지를 알 수 있는 손실함수를 정의하고 W가 존재하는 모든 공간에서 손실함수를 최소화 할 수 있는 W를 찾는 것이다.

먼저 살펴볼 손실함수는 SVM 손실이다.

![사진2](https://user-images.githubusercontent.com/77263283/131453334-c8747a66-5b45-40ca-868f-759e0d8a4ddc.png)

손실 L_i는 target이 아닌 카테고리 스코어(S_j)와 target 카테고리 스코어(S_Y_i)를 비교하여 그 손실 값을 모두 더한값이다.  만약, target 카테고리 스코어 값이 다른 카테고리 스코어보다 크다면, 그리고 일정 마진 보다 크다면 그 손실값은 0이 될것이다. target 카테고리의 L_i값을 제외한 모든 L_i값을 더하면 그것이 그 샘플의 총 손실 값이 된다. 또한 각 샘플의 최종 손실 값을 더해 평균을 취하면 그것이 최종 손실값이 된다.

실제 연산은 어떻게 되는지 예제로 살펴보자.

![사진3](https://user-images.githubusercontent.com/77263283/131453358-faddd3f0-f307-41d8-8652-0d23443c8296.png)

위 사진처럼 세개의 이미지는 세개의 카테고리중 하나로 분류된다.

첫 번째 사진의 target 스코어는 3.2이다. 이 이미지의 손실 값을 구해보자. 먼저 target 카테고리를 제외한 모든 다른 카테고리 스코어와 target 카테고리 스코어를 비교해야한다. 자동차 카테고리의 스코어는 5.1이다. 따라서 자동차 카테고리의 손실값은 max(0,5.1-3.2+1)로 2.9가 된다. 다음으로 개구리 카테고리의 손실값을 구하면 max(0,-1.7-3.2+1)로 0이된다. 따라소 이 고양이 이미지에 대한 손실 값은 2.9+0으로 2.9가 된다.

![사진4](https://user-images.githubusercontent.com/77263283/131453394-c57a49ed-fdca-4502-acd6-03b370e361b1.png)

다음으로 두번째 이미지의 손실 값을 구해보자. 이 사진의 target 카테고리는 자동차이다. 따라서 다른 카테고리와 자동차 카테고리의 스코어를 비교하고 이 합이 두번째 이미지의 손실 값이 된다. 자동차 카테고리의 스코어는 다른 카테고리 스코어보다 매우 높으므로 이 이미지의 손실값은 0이 된다.
