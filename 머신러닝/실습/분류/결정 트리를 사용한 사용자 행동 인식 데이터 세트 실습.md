## 결정 트리를 사용한 사용자 행동 인식 데이터 세트 실습

결정 트리를 이용해 UCI 머신러닝 리포지토리에서 제공하는 사용자 행동 인식 데이터 세트에 대한 예측 분류를 수행해 보자. 해당데이터는 30명에게 스카트폰 센서를 장착한 뒤 사람의 동작과 관련된 여러 가지 피처를 수집한 데이터이다.

수집된 피처 세트를 기반으로 결정 트리를 이용해 어떠한 동작인지 예측해 보자.

```python
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline

#features.txt. 파일에는 피처이름 index와 공백으로 분리되어 있음. 이를 DataFrame으로 로드.
feature_name_df =pd.read_csv('./human_activity/features.txt',sep='\s+',header=None,names=['column_index','column_name'])

#피처명 index를 제거하고, 피처명만 리스트 객체로 생성한 뒤 샘플로 10개만 추출
feature_name=feature_name_df.iloc[:,1].values.tolist()
print('전체 피처명에서 10개만 추출:', feature_name[:10])
```

[output]

전체 피처명에서 10개만 추출: ['tBodyAcc-mean()-X', 'tBodyAcc-mean()-Y', 'tBodyAcc-mean()-Z', 'tBodyAcc-std()-X', 'tBodyAcc-std()-Y', 'tBodyAcc-std()-Z', 'tBodyAcc-mad()-X', 'tBodyAcc-mad()-Y', 'tBodyAcc-mad()-Z', 'tBodyAcc-max()-X']

피쳐명을 보면 인체의 움직임과 괸련된 속성의 평균/표준편차가  X,Y,Z축 값으로 되어 있음을 유추할 수 있다. 위에서 피처명을 가지고 있는 features.txt. 파일은 중복된 피처명을 가지고 있다. 따라서 중복된 피처명에 대해서는 원본 피처명에 _1 또는 _2를 추가로 부여해 벼경한 뒤에 이를 이용해서 데이터를 DataFrame에 로드해야한다.

```python
feature_dup_df=feature_name_df.groupby('column_name').count()
print(feature_dup_df[feature_dup_df['column_index']>1].count())
feature_dup_df[feature_dup_df['column_index']>1].head()
```

[output]

![결과1](https://user-images.githubusercontent.com/77263283/124248321-b16bb700-db5d-11eb-9b0e-3e637fa1ccba.png)

총 42개의 피처명이 중복되어 있다. 이 중복된 피처명에 대해서는 원본 피처명에 *1또는 2를* 추가로 부여해 새로운 피처명을 가지는 DataFrame을 반환하는 함수인 get_nea_feature_name_df()을 생성하겠다.

```python
def get_new_feature_name_df(old_feature_name_df):
    feature_dup_df=pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),columns=['dup_cnt'])
    feature_dup_df=feature_dup_df.reset_index()
    new_feature_name_df=pd.merge(old_feature_name_df.reset_index(),feature_dup_df,how='outer')
    new_feature_name_df['column_name']=new_feature_name_df[['column_name','dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) 
                                                                                            if x[1]>0 else x[0], axis=1)
    new_feature_name_df=new_feature_name_df.drop(['index'],axis=1)
    return new_feature_name_df
```

이제  train데이터와 test데이터를  DataFrame에 로드해보자. 레이블의 명명은 'action'으로 하겠다.

```python
def get_human_dataset():
    
    #각 데이터 파일은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.
    feature_name_df=pd.read_csv('./human_activity/features.txt',sep='\s+',header=None,names=['column_index','column_name'])
    
    #중복된 피처명을 수정하는 함수를 이용하여 신규 피처명 DataFrame생성.
    new_feature_name_df=get_new_feature_name_df(feature_name_df)
    
    #DataFrame에 피처명을 칼럼으로 부여하기 위해 리스트 객체로 다시 변환
    feature_name=new_feature_name_df.iloc[:,1].values.tolist()
    
    #학습 피처 데이터 세트와 테스트 피처 데이터를 DataFrame으로 로딩, 칼럼명은 feature_name 적용
    X_train=pd.read_csv('./human_activity/train/X_train.txt',sep='\s+',names=feature_name)
    X_test=pd.read_csv('./human_activity/test/X_test.txt',sep='\s+',names=feature_name)
    
    #학습 레이블과 테스트 레이블 데이터를  DataFrame으로 로딩하고 칼럼명은 action으로 부여
    y_train=pd.read_csv('./human_activity/train/y_train.txt',sep='\s+',header=None,names=['action'])
    y_test=pd.read_csv('./human_activity/test/y_test.txt',sep='\s+',header=None,names=['action'])
    
    #로드된 학습/테스트용 DataFrame을 모두 반환
    return X_train,X_test,y_train,y_test
X_train,X_test,y_train,y_test=get_human_dataset()
```

로드한 학습용 피처 데이터 세트를 간략히 살펴보자.

```python
print('## 학습 피처 데이터셋 info()')
print(X_train.info())
```

[output]

![결과2](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/18dda75a-ae9f-4b7c-bc7e-d151a6b6d212/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210607%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210607T154214Z&X-Amz-Expires=86400&X-Amz-Signature=5251498b20d075056122bf2b7c5017988d3bb4756e13ff5caa2feb9e22ffc808&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

피처가 전부 float형의 숫자 형이므로 별도의 카테고리 인코딩은 수행할 필요가 없다.

```python
print(y_train['action'].value_counts())
```

[output]

![결과3](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e5c2df05-332d-43f9-8cae-0a354751ef6a/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210607%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210607T154243Z&X-Amz-Expires=86400&X-Amz-Signature=39947c48f8ac562a5ffe5afd91becdaae0c3e04657d7af160d15b22f2bf88ac2&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

레이블 값은 1,2,3,4,5,6의 6개 값이고 분포도는 특정 값으로 왜곡되지 않고 비교적 고르게 분포되어 있다.

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

dt_clf=DecisionTreeClassifier(random_state=0)
dt_clf.fit(X_train,y_train)
pred=dt_clf.predict(X_test)
accuracy=accuracy_score(y_test,pred)
print('결정 트리 예측 정확도:{0:.4f}'.format(accuracy))
```

[output]

![결과4](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/25f0fa65-79c4-4f7e-bb56-1b56b3055733/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210607%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210607T154309Z&X-Amz-Expires=86400&X-Amz-Signature=ed8c22bd0e1c273ea94c55b8ec07c779c2570a5a5ce02ba8b701449b1ca43b28&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

하이퍼 파라미터를 조정하지 않았을 때의 정확도는 약85.95%이다.

이번에는 결정 트리의 깊이가 예측 정확도에 주는 영향을 살펴보자. 

GridSearchCV를 이용해 max_depth 값을 변화시키면서 예측 성능을 측정한다.

```python
from sklearn.model_selection import GridSearchCV

params={'max_depth':[6,8,10,12,16,20,24]}
grid_cv=GridSearchCV(dt_clf,param_grid=params, scoring='accuracy',cv=5,verbose=1)
grid_cv.fit(X_train,y_train)
print('GridSearchCV 최고 평균 정확도 수치:{0:.4f}'.format(grid_cv.best_score_))
print('GridSearchCV 최적 하이퍼 파라미터:',grid_cv.best_params_)
```

[output]

![결과5](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/da56663d-2d33-403c-9cbf-4ed723f2f988/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210607%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210607T154345Z&X-Amz-Expires=86400&X-Amz-Signature=d824622bbd32a3a1bd6b3df7e3389a4b81bf8fd10dd45cfca21ab14ee5b285a2&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

max_depth가 10일 때 5개의 폴드 세트의 최고 평균 정확도 결과가 약 84.81%로 도출되었다.

5개의  CV세트에서 max_depth 값에 따라 어떻게 예측 성능이 변했는지 살펴보자.

```python
#GridSearchCV 객체릐 cv_results_ 속성을 DAtaFrame으로 생성.
cv_results_df=pd.DataFrame(grid_cv.cv_results_)

#max_depth 파라미터 값과 그때의 테스트 세트, 학습 데이터 세트의 정확도 수치 추출
cv_results_df[['param_max_depth','mean_test_score']]
```

[output]

![결과6](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/2f3aa1f7-3660-47ec-95d8-28cb3b93e78e/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210607%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210607T154414Z&X-Amz-Expires=86400&X-Amz-Signature=a7581ad3bd7462e3e397e2d756578bbcc167cf8564212c8d7ffed682220addb5&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

mean_test_scores는 max_depth가 10일 때 0.848로 정확도가 정점이고, 이를 넘어가면서 정확도가 계속 떨어진다.

결정트리는 더 완변한 규칙을 학습 데이터 세트에 적용하기 위해 노드를 지속적으로 분할하면서 깊이가 깊어지고 더욱 더 복잡한 모델이 된다. 깊어진 트리는 검증 데이터 세트에서는 오히려 과적합으로 인한 성능 저하를 유발하게 된다.

이번에는 별도의 테스트 데이터 세트에서 결정 트리의 정확도를 측정해 보자.

```python
max_depth=[6,8,10,12,16,20,24]

#max_depth 값을 변화시키면서 그때마다 학습과 테스트 세트에서의 예측 성능 측정
for depth in max_depth:
    df_clf=DecisionTreeClassifier(max_depth=depth,random_state=0)
    df_clf.fit(X_train,y_train)
    pred=df_clf.predict(X_test)
    accuracy=accuracy_score(y_test,pred)
    print('max_depth={0} 일때 정확도 {1:.4f}'.format(depth,accuracy))
```

[output]

![결과7](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/17a12cb5-4229-440d-bfdf-8dfa94da6814/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210607%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210607T154440Z&X-Amz-Expires=86400&X-Amz-Signature=61f8663c230722b1cb76a0fdbe02f24ef2a154bc29ba276320dd970d98a94c2a&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

max_depth가 8일 때 약87.07%로 가장 높은 정확도를 나타냈다. 앞의  GridSearchCV 예제와 마찬가지로 깊이가 깊어질수록 테스트 데이터 세트의 정확도는 더 떨어진다.

이처럼 결정 트리는 깊이가 깊어질수록 과적합의 영향력이 커지므로 하이퍼 파라미터를 이용해 깊이를 제어할 수 있어야 한다.

```python
params={'max_depth':[6,8,10,12,16,20,24],
       'min_samples_split':[16,24]}
grid_cv=GridSearchCV(dt_clf,param_grid=params, scoring='accuracy',cv=5,verbose=1)
grid_cv.fit(X_train,y_train)
print('GridSearchCV 최고 평균 정확도 수치:{0:.4f}'.format(grid_cv.best_score_))
print('GridSearchCV 최적 하이퍼 파라미터:',grid_cv.best_params_)
```

[output]

![결과8](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/05cee116-7e59-4903-b2a5-a3e00b1b75e6/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210607%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210607T154504Z&X-Amz-Expires=86400&X-Amz-Signature=4612befa56f7a57850f9ee1f3d7280c64bd0ce9293723c316ae9a08fd05c3d7d&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

max_depth가 8일 때 약85.11%로 가장 높은 정확도를 나타냈다.  

이번엔 앞의 결과로 나온 최적의 하이퍼 파라미터를 적용하여 별도의 테스트 세트에 예측을 수행해보자.

```python
best_dt_clf=grid_cv.best_estimator_
pred1=best_df_clf.predict(X_test)
accuracy=accuracy_score(y_test,pred1)
print('결정 트리 예측 정확도:{0:.4f}'.format(accuracy))
```

[output]

![결과9](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ed3855fd-0273-48cb-bb10-20893ffaaff6/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210607%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210607T154538Z&X-Amz-Expires=86400&X-Amz-Signature=2063cc65008d1dabad0fb3ab7ea5f697258ab9268dc8154d5e9a8127e8658f34&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

마지막으로 각 피처의 중요도를 높은 순으로 Top 20 피처를 막대그래프로 표현해보자.

```python
import seaborn as sns

ftr_importances_values=best_dt_clf.feature_importances_

#Top 중요도로 정렬을 쉽게 하고, 시본의 막대그래프로 쉽게 표현하기 위해 Series 변환
ftr_importances=pd.Series(ftr_importances_values,index=X_train.columns)

#중요도값 순으로 Series를 정렬
ftr_top20=ftr_importances.sort_values(ascending=False)[:20]
plt.figure(figsize=(8,6))
plt.title('Feature importances Top 20')
sns.barplot(x=ftr_top20,y=ftr_top20.index)
plt.show()
```

[output]

![결과10](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7233b502-24e7-4dc6-9d22-41ba3c90a277/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210607%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210607T154603Z&X-Amz-Expires=86400&X-Amz-Signature=30204f7122fb601856b9699222bc6cce971fc471972bde7e28362143db5e3fc0&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

막대 그래프 상에서 확인해 보면 이 중 가장 높은 중요도를 가진 Top 5의 피처들이 매우 중요하게 규칙 생성에 영향을 미치고 있는 것을 알 수 있다.
