## 파이썬으로 구현한 경사 하강법

간단한 회귀식인 y=4X+6을 근사하기 위한 100개의 데이터 세트를 만들고, 여기에 경사 하강법을 이용해 회귀 계수 w1,w0을 도출해 보자.

```python
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

np.random.seed(0)
#y = 4X + 6을 근사(w1=4,w0=6). 임의의 값은 노이즈를 위해 만듦
X = 2 * np.random.rand(100,1)
y=6+4*X+np.random.rand(100,1)

#X,y 데이터 세트 산점도로 시각화
plt.scatter(X,y)
```

[output]

![결과](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/3ef8846a-8344-402e-b709-1585b4dce9ff/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210613%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210613T134824Z&X-Amz-Expires=86400&X-Amz-Signature=79386f8c2b24d89af1ead6b8f936c9393931d40084444fc8071642c392c3555a&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

데이터는 y=4X+6을 중심으로 무작위로 퍼져있다. 

```python
#w1과 w0을 업데이트할 w1_update, w0_update를 반환.
def get_weight_updates(w1,w0,X,y,learning_rate=0.01):
  N=len(y)
  #먼저 w1_update, w0_update를 각각 w1,w0의 shape와 동일한 크기를 가진 0 값으로 초기화
  w1_update=np.zeros_like(w1)
  w0_update=np.zeros_like(w0)
  #예측 배열 계산하고 예측의 실제 값의 차이 계산
  y_pred=np.dot(X,w1.T)+w0
  diff=y-y_pred
  #w0_update를 dot 행렬 연산으로 구하기 위해 모두 1 값을 가진 행렬 생성
  w0_factors=np.ones((N,1))

  #w1과 w0을 업데이트할 w1_update와 w0_update 계산
  w1_update=-(2/N)*learning_rate*(np.dot(X.T,diff))
  w0_update=-(2/N)*learning_rate*(np.dot(w0_factors.T,diff))

  return w1_update, w0_update
  
#입력 인자 iters로 주어진 횟수만큼 반복적으로 w1과 w0를 업데이트 적용함
def gradient_descent_steps(X,y,iters=1000):
  #w0와 w1을 모두 0으로 초기화.
  w0=np.zeros((1,1))
  w1=np.zeros((1,1))

  #인자로 주어진 iters만큼 반복적으로 get_weight_updates() 호출해 w1,w0업데이트 수행
  for ind in range(iters):
    w1_update,w0_update=get_weight_updates(w1,w0,X,y,learning_rate=0.01)
    w1-=w1_update
    w0-=w0_update

  return w1,w0

def get_cost(y,y_pred):
  N=len(y)
  cost=np.sum(np.square(y-y_pred))/N
  return cost

w1,w0=gradient_descent_steps(X,y,iters=1000)
print("w1:{0:.3f} w0:{1:.3f}".format(w1[0,0],w0[0,0]))
y_pred=w1[0,0]*X+w0
print('Gradient Descdent Totla Cost:{0:.4f}'.format(get_cost(y,y_pred)))
```

[output]

![결과2](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a4be566a-5ef4-4204-83e0-b19bf21c9296/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210613%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210613T134907Z&X-Amz-Expires=86400&X-Amz-Signature=536d691ab49157f5291498eae7710b871ddd4ed4f7602ebcad832eb94dff26f7&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

실행결과 실제 선형식인 y=4*X+6과 유사하게 w1은 4.028, w0은 6.490이 도출되었다.

앞에서 구한 y_pred에 기반해 회귀선을 그려보자.

```python
plt.scatter(X,y)
plt.plot(X,y_pred)
```

[output]

![결과3](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7d6e5826-0e3c-433c-bbb1-a86162a57704/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210613%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210613T134848Z&X-Amz-Expires=86400&X-Amz-Signature=784f974cd0fb3f7954a51626f474b88c04027814eb145c0e9448a0821eaf3ef8&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

경사하강법을 이용해 회귀선이 잘 만들어졌음을 알 수 있다.
