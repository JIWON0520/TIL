## 산탄데르 고객 만족 예측

캐글의 산탄데르 고객 만족 예측 데이터 세트에 대해서 고객 만족 여부를 XGBoost와 LightGBM을 활용해 예측해 보자.

산탄데르 고객 만족 예측 분석은 370개의 피처로 주어진 데이터 세트를 기반에서 고객 만족 여부를 예측하는 것이다. 클레스 레이블 명은 Target이며 이 값이 1이면 불만을 가진 고객, 0이면 만족한 고객이다. 모델의 성능 평가는 ROC-AUC로 평가한다. 대부분이 만족이고 일부분이 불만족 데이터 일것이므로 정확도 보다는 ROC-AUC가 더 적합하다.

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib

cust_df=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/santander countomer satisfaction/train.csv",encoding='latin-1')
print('dataset shape:',cust_df.shape)
cust_df.head(3)
```

[output]

![결과1](https://user-images.githubusercontent.com/77263283/124486089-35d16a80-dde8-11eb-830e-d20f881cfb55.png)

클래스 값을 포함해서 371개의 피쳐값이 존재한다.

피처의 타입과 NULL값을 알아보자.

```python
cust_df.info()
```

[output]

![결과2](https://user-images.githubusercontent.com/77263283/124486105-38cc5b00-dde8-11eb-82c0-945650536107.png)

피처의 타입은 모두 숫자형이고 NULL값은 없다.

전체 데이터에서 만족과 불만족의 비율을 살펴보자.

```python
print(cust_df["TARGET"].value_counts())
unsatisfied_cnt=cust_df[cust_df['TARGET']==1].TARGET.count()
total_cnt=cust_df.TARGET.count()
print('unsatisfied 비율은 {0:.2f}'.format((unsatisfied_cnt/total_cnt)))
```

[output]

![결과3](https://user-images.githubusercontent.com/77263283/124486118-3c5fe200-dde8-11eb-845a-f78458e997aa.png)

대부분이 만족이며 불만족인 고객은 얼마 되지 않는4%에 불과하다.

```python
cust_df.describe()
```

[output]

![결과4](https://user-images.githubusercontent.com/77263283/124486125-3e29a580-dde8-11eb-996a-9d73a7a87370.png)

피처들중 var3을 보면 min값이 -999999이다. 특정 예외값을 -999999로 변환했을 것이다.

```python
print(cust_df.var3.value_counts()[:10])
```

[output]

![결과5](https://user-images.githubusercontent.com/77263283/124486138-41249600-dde8-11eb-9821-c1098f7e8cb0.png)

실제로 위의 출력 결과를 보면 -999999값이 116개나 있음을 알 수 있다. -999999값을 가장 많은 2로 변환하겠다. 또한 ID피처는 단순 식별자에 불과하므로 삭제하겠다.

```python
cust_df['var3'].replace(-999999,2,inplace=True)
cust_df.drop('ID',axis=1,inplace=True)

#피처세트와 레이블 세트 분리. 레이블 칼럼은 DataFrame의 맨 마지막에 위치해 칼럼 위치 -1로분리
X_featrue=cust_df.iloc[:,:-1]
y_labels=cust_df.iloc[:,-1]
print('피처 데이터 shape:{0}'.format(X_fearue.shape))
```

[output]

![결과6](https://user-images.githubusercontent.com/77263283/124486155-441f8680-dde8-11eb-8181-d0b4126b64e4.png))

학습과 성능 평가를 위해서 원본 데이터 세트에서 학습 데이터 세트와 테스트 데이터 세트를 분리하겠다. 비대칭한 데이터 세트이므로 클래스인 Target값 분포도가 학습데이터와 테스트 데이터세트에 모두 비슷하게 추출되었는지 확인도하자.

```python
from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X_feature,y_labels,test_size=0.2,random_state=0)

train_cnt=y_train.count()
test_cnt=y_test.count()
print('학습 세트 Shape:{0}, 테스트 세트 Shape:{1}'.format(X_train.shape,X_test.shape))

print('학습 세트 레이블 분포 비율')
print(y_train.value_counts()/train_cnt)
print('테스트 세트 레이블 분포 비율')
print(y_test.value_counts()/test_cnt)
```

[output]

![결과7](https://user-images.githubusercontent.com/77263283/124486166-471a7700-dde8-11eb-9aa4-023a5fbdeaa9.png)

학습과 테스트 데이터 세트 모두 Target값의 분포가 원본 데이터와 유사하게 전체 데이터의 4%정도의 불만족 겂으로 만들어졌다.

### XGBoost 모델 학습과 하이퍼 파라미터 튜닝

XGBoost를 이용하여 학습과 테스트를 진행해 보자.

```python
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score

#n_estimators는 500으로, random state는 예제 수행 시마다 동일 예측 결과를 위해 설정.
xgb_clf=XGBClassifier(n_estimators=500, random_state=0)

#성능 평가 지표를 auc로, 조기 중단 파리미터는 100으로 설정하고 학습 수행
xgb_clf.fit(X_train,y_train, early_stopping_rounds=100, eval_metric="auc",eval_set=[(X_train,y_train),(X_test,y_test)])

xgb_roc_score=roc_auc_score(y_test,xgb_clf.predict_proba(X_test)[:,1],average='macro')
print('ROC AUC:{0:.4f}'.format(xgb_roc_score))
```

[output]

![결과8](https://user-images.githubusercontent.com/77263283/124486173-4a156780-dde8-11eb-97d6-c0383e4f775a.png)

....

![결과9](https://user-images.githubusercontent.com/77263283/124486193-4e418500-dde8-11eb-9c51-43735493105b.png)

178번 반복하고 조기종료 하였다. 테스트 데이터로 예측시 ROC AUC는 약 0.8419이다

다음으로 XGBoost의 하이퍼 파라미터를 튜닝해보자.

```python
from sklearn.model_selection import GridSearchCV

#하이퍼 파라미터 테스트의 수행 속도를 향상시키기 위해 n_estimators를 100으로 감소
xgb_clf=XGBClassifier(n_estimators=100, random_state=0)

params={'max_depth':[5,7],'min_child_wegiht':[1,3],'colsample_bytree':[0.5,0.75]}

#cv는 3으로 지정
grid_cv=GridSearchCV(xgb_clf, param_grid=params, cv=3)
grid_cv.fit(X_train,y_train,early_stopping_rounds=30,eval_metric='auc',eval_set=[(X_train,y_train),(X_test,y_test)])

print('GridSearchCV 최적 파라미터:',grid_cv.best_params_)

xgb_roc_auc=roc_auc_score(y_test,grid_cv.predict_proba(X_test)[:,1],average='macro')
print('ROC AUC:{0:.4f}'.format(xgb_roc_score))
```

[output]

![결과10](https://user-images.githubusercontent.com/77263283/124486206-526da280-dde8-11eb-8853-a524fd74d0ab.png)

하이퍼 파라미터 colsample_bytree가 0.5, max_depth가 5, min_child_wegiht가 1일 때, ROC AUC가 약 0.8461로 개선되었다.

마지막으로 각 피처의 중요도를 피처 중요도 그래프로 나타내보자.

```python
xgb_roc_auc=roc_auc_score(y_test,grid_cv.predict_proba(X_test)[:,1],average='macro')
print('ROC AUC:{0:.4f}'.format(xgb_roc_auc))
```

[output]

![결과11](https://user-images.githubusercontent.com/77263283/124486221-54cffc80-dde8-11eb-9923-2c9b2de4de2f.png)2)

### LightGBM 모델 학습과 하이퍼 파라미터 튜닝

앞의 예제 코드에서 만들어진 데이터 세트를 기반으로 LightGBM으로 학습을 수행하고, ROC-AUC를 측정해 보자.

```python
from lightgbm import LGBMClassifier

lgbm_clf=LGBMClassifier(n_estinators=500)

evals=[(X_test,y_test)]
lgbm_clf.fit(X_train,y_train,early_stopping_rounds=100, eval_metric='auc',eval_set=evals, verbose=True)

lgbm_roc_score=roc_auc_score(y_test,lgbm_clf.predict_proba(X_test)[:,1],average='macro')
print('ROC AUC:{0:.4f}'.format(lgbm_roc_score))
```

[output]

![결과12](https://user-images.githubusercontent.com/77263283/124486241-58fc1a00-dde8-11eb-8200-4e5bb7bc9097.png)
LightGBM 수행 결과 ROC AUC가 약 0.8396을 나타낸다.

이번에는 GirdSearchCV로 하이퍼 파라미터 튜닝을 수행해 보자.

```python
#하이퍼 파라미터 테스트의 수행 속도를 향상시키기 위해 n_estimators를 200으로 감소
lgbm_clf=LGBMClassifier(n_estimators=200)

params={'num_leaves': [32,64],
        'max_depth':[128,160],
        'min_child_samples':[60,100],
        'subsample':[0.8,1]}

#cv는 3으로 지정
grid_cv=GridSearchCV(lgbm_clf,param_grid=params,cv=3)
grid_cv.fit(X_train,y_train, early_stopping_rounds=30, eval_metric='auc', eval_set=evals)

print("GridSearchCV 최적 하이퍼 파라미터:",grid_cv.best_params_)
lgbm_roc_score=roc_auc_score(y_test,grid_cv.predict_proba(X_test)[:,1],average='macro')
print("ROC AUC:{0:.4f}".format(lgbm_roc_score))
```

[output]

![결과13](https://user-images.githubusercontent.com/77263283/124486286-65807280-dde8-11eb-9310-227cf683be2e.png)
해당 하이퍼 파라미터를 LightGBM에 적용하고 다시 학습해 ROC-AUC 측정 결과를 도출해 보자.

```python
lgbm_clf=LGBMClassifier(n_estimators=1000, num_leaves=32,max_depth=128,min_child_samples=100,subsample=0.8)

lgbm_clf.fit(X_train,y_train,early_stopping_rounds=100, eval_metric='auc',eval_set=evals,verbose=True)

lgbm_roc_score=roc_auc_score(y_test,lgbm_clf.predict_proba(X_test)[:,1], average='macro')
print("ROC AUC:{0:.4f}".format(lgbm_roc_score))
```

[output]

![결과14](https://user-images.githubusercontent.com/77263283/124486295-6913f980-dde8-11eb-9349-c21bf6d853d8.png)

LightGBM의 경우 테스트 데이터 세트에서 ROC-AUC가 약 0.8442로 측정되었다.
