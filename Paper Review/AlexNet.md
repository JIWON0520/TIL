# ImageNet Classification with Deep Convolutional Neural Networks

## Abstract

1000개의 카테고리를 가지는 1.2백만개의 이미지 classification하기 위해서 더 많은 파라미터와 뉴런들을 이용해서 CNN을 구성하였다.

5개의 cnn 층과(몇개의 층은 max pooling층을 가짐) 3개의 완전 연결층을 가진다.

학습 시간을 단축하기 위해서 비  포화 뉴런(non-saturating neurons)과 연산에 매우 효과적인GPU수행을 적용하였다.

완전 연결 층에서의 오버피팅을 방지하기 위해 드롭아웃 이라는 효과적인 규제을 사용하였다.

ILSVRC-2010대회에서 최신 기술보다 뛰어난 성능인 top-1,top-5 에러율 37.5%,17.0%를 달성하였고, 이 모델의 변형을 이용하여 ILSVRC-2012에서 top-5오류율(정답 라벨이 모델이 예측한 가능성있는 다섯개의 라벨에 속하지 않는 이미지의 비율)정답 이 15.3%로 2위인 26.2%보다 뛰어난 성능을 보였다.

 

<aside>
💡 비 포화 뉴런(non-saturating neuron): 어떤 입력 x가 무한대로 갈때 함수의 값이 무한대로 가는 것  ex)Relu

💡  포화 뉴런(saturating neuron):어떤 입력 x가 무한대로 갈 때 함수의 값은 특정 범위내에서만 움직이는 것 ex) sigmoid

</aside>

## 1. Introduction

최근까지의 데이터 셋은 수 만개의 이미지 셋으로 상대적으로 작았다.  단순한 이미지 인식 작업은 라벨 보존 변형으로 데이터셋을 증식하면 꽤 잘 수행되었다. 

하지만 실제 환경에서의 사물은 다양해서 이것을 학습 시키기 위해서는 매우 큰 학습 데이터 셋이 필요하다. 실제로 작은 데이터 셋의 단점은 널리 알려지고 있지만, 최근에 라벨링이 된 수 백만개의 이미지 수집이 가능해 졌다.

LabelMe,ImageNet과 같은 큰 데이터 셋은 실제로 많은 양의 이미지를 가지고 있다. 이런 큰 데이터 셋을 학습시키기 위해서는 더 큰 학습 수용량을 가지는 모델이 필요하다. 

하지만 이 사물 인식의 복잡성은 ImageNet처럼 큰 데이터 셋으로도 구체화될 수 없으므로 우리가 가지고 있지 않은 데이터를  보완 할 수 있게 사전 지식을 가져야 한다. 

CNN은 그러한 모델을 구성한다. 그들의 용량은 깊이와 폭의 조절을 통해 제어 할 수 있고, 그들은 이미지의 특성에 대해 더 강하고 정확한 가정을 한다.

비슷한 사이즈의 다른 neural network와 비교해 봤을 때, 이론적인 최고 성능은 약간 떨어지더라도 cnn은 더 적은 연결과 파라미터를 가지고 있어서 학습이 더 쉽다. 

이 매력적인 CNN의 특성과  로컬 아키텍쳐의 상대적인 효율성에도 불구하고 이를 높은 해상도의 이미지에 적용시키는 비용은 매우 크다.

하지만 다행스럽게도, 최근 GPU는 이 거대한 CNN을 학습하기에 충분히 강력하고, ImageNet같은 최근 큰 데이터 셋은 심각한 오버피팅을 방지할 수 있을 만큼 충분한 라벨링 데이터가 포함되어 있다.

이 논문의 구체적은 기여는 다음과 같다.

- ILSVRC-2010,ILSVRC-2012에 사용된 ImageNet에 대해 지금까지 가장 큰 CNN을 학습 시켰고, 이 데이터 셋에 대해 보고된 성과 중 최고를 달성했다.
- 2D convolution 구현에 최적화 된 GPU를 사용하였다.
- 학습 시간을 단축하고 성능을 올리기 위해서 새롭고 특이한 특징들을 사용하였다.
- 1.2백만개의 라벨링 된 데이터 셋이라고 해도, 오버피팅의 문제가 있는데 그래서 오버피팅을 방지하는 효과적인 기술을 사용했다.
- 최종 모델은 5개의 convolutional층과 3개의 완전 연결층으로 구성되었는데 그 깊이는 중요하다. 어떤 convolutional층을 제거해도 떨어지는 성능을 보였다.

## 2. The Dataset

이미지 분류 대회인 ILSVRC는 2010년 부터 시작되었다. 이 대회에서는 ImageNet 데이터의 서브셋을 사용한다. 대략 1.2백만개의 학습 데이터, 50,000개의 검증 데이터, 150,000개의 테스트 데이터이다. ILSVRC-2010은 테스트 세트의 라벨을 이용할 수 있기 때문에 우리의 대부분의 실험을 했다. (뒤에 ILVRC-2012의 데이터세트에 적용한 결과도 있음. 이 버전의 테스트 데이터 세트의 라벨은 이용불가임)  

우리의 모델은 일정한 차원이 필요한데, ImageNet은 다양한 해상도로 구성되어 있기 때문에 우리는 이미지를 256X256으로 다운 샘플링하였다. 학습 세트의 각 픽셀에 평균 activity값을 빼는것 외에 이미지 전처리를 하지 않았다. 그래서 우리는 픽셀의 RGB값을 그대로 학습하였다.

## 3.The Architecture

네트워트의 구성은 총 여덟개의 층으로 구성되어 있다. 네트워트 구성에서 특이한 특징들을 중요한 순서대로 나열하였다.

### 3.1 ReLU Nonlinearity

각 뉴런의 출력인 입력을 x로 가지는 함수 f는  f(x)=tanh(x)이거나 f(x)=(1+e^-x)^-1이다. 경사 하강법을 이용한 학습 과정의 관점에서 이 포화 비선형성은 불포화 비선형성(f(x)=max(0,x))보다 느리다. 우리는 이 비선형성을 가지는 뉴런을 ReLU라고 지칭하자. 이 ReLU를 가진 CNN은 tnah를 가지는 동등한 모델 보다 학습 시간이 빠르다. 옆의 사진을 보면 점선이 tanh 함수이고 실선이 ReLU 함수이다. 같은 데이터세트를 사용했을 때, ReLU함수가 오류율 0.25를 달성하는데 더 적은 iteration을 가지는 것을 알 수 있다.

![image](https://user-images.githubusercontent.com/77263283/151334135-4079d61f-5053-45e5-b359-b56776e39a31.png)

### 3.2 Training on Multiple GPUs

1.2백만개의 이미지 데이터 셋은 하나의 GPU에서 학습되기에 큰 데이터 세트이다. 그래서 우리는 두개의 GPU를 이요아여 학습을 진행하였다. 두 개의 GPU병렬화에서 각각의 GPU는 총 커널의 절반의 연산을 수행하였다. 이때 추가적인 트릭이 존재한다. GPU는 특정층에서만 교류한다는 것이다. 예를 들어 layer3은 layer2의 모든 출력을 입력으로 사용하는 반면, layer4는 같은 GPU에 존재하는 layer3의 출력만을 입력으로 사용한다. 

커널의 절반만 사용해서 하나의 GPU로 학습한 결과와 비교해, 2개의 GPU를 사용해서 학습한 top-1,top-5오류율은 각각 1.7%, 1.2%감소했다. 그리고 두개의 GPU를 이용하면 학습시간을 단축 할 수 있다.

### 3.3 Local Response Normalization

ReLU함수는 입력의 정규화가 필요없다. 하지만 지역 정규화(LRN)는 일반화를 돕는다. LRN은 어떤 커널의 활성 값이 주면 커널의 활성 값보다 훨씬 클 때, 주변 커널의 활성 값이 억제되는 현상을 막기위해 사용된다.

커널 i의 (x,y)자리에서 활성된 a의 정규화된 값 b는 다음과 같은 식을 통해 도출된다.

![image](https://user-images.githubusercontent.com/77263283/151334274-76dbbe8c-84e5-4c44-806b-6ac5274b237d.png)

주변 커널의 활성값을 더한뒤, 파라미터 α를 곱하고 k를 더해준 값을 분모로하여 정규화한다.

이 LRN은 top-1,top-5 오류율을 1.4%,1.2% 줄여주었다.

### 3.4 Overlapping Pooling

Pooling 층은 같은 커널에서 인접한 그룹의 값을 요약해준다. 

전통적으로 zXz 사이즈의 pooling  map과 s 크기의 stride로 pooling을 수행한다고 하자.  z=s를 사용하면 pooling map이 겹치지 않는 non_overlapping pooling이다. s<z이면 pooling map이 겹쳐지게 되는 overlapping Pooling이다. 이 pooling방법은 non-overlapping pooling과 비교했을 때 top-1, top-5 오류율을 0.4%, 0.3% 줄여주었다. 그리고 over pooling은 오버피팅을 조금 막아주었다.

![image](https://user-images.githubusercontent.com/77263283/151334335-d9142003-e45e-4ab9-9139-edf1f1ab6de2.png)

### 3.5 Overall Architecture

![image](https://user-images.githubusercontent.com/77263283/151334390-235475c1-1db6-4e7f-b6c1-3ec8b244f02c.png)

CNN의 구성은 총 여덟개의 층으로 구성되어 있다. 5개의 convolutional layer와 3개의 완전 연결층이다. 마지막 완결연결층의 출력은 softmax의 입력으로 들어가 1000개의 카테고리의 확률 값으로 나온다. 

두번째, 네번째, 다섯번째 층은 같은 GPU에 있는 커널 맵과 연결되고, 세번째 층은 두번째 층의 모든 커널맵과 연결되어 있다.  완전 연결층은 이전층의 모든 뉴런들과 연결되어 있다. LRN층은 첫번째, 두번째 층 뒤에 존재하고, max pooling층은 첫번째, 두번째, 다섯번째 층 뒤에 온다. ReLU함수는 모든 층에 적용된다.

첫번째 층은 224X224X3의 입력 이미지를 크기가 11X11X3인 96개의 커널로 필터링 한다.

두번째 층은 첫번째 층의 출력(LRN과 max pooling된)을 입력으로 사용하여 5X5X48인 커널 256개를 사용한다.

세번째 층은 두번째 층의 출력(LRN과 max pooling된)을 입력으로 3X3X128크기의 384개의 커널을 사용한다.

네번째 층은 3X3X192크기의 384개의 커널을 사용한다.

다섯번째 층은 3X3X192크기의 256개의 커널을 사용한다.

세 개의 완전 연결층은 각 4096개의 뉴련을 입력으로 한다.
